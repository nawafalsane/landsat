{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.metrics import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('parrot.pkl', 'rb') as f:\n",
    "    ndvi_lst = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.read_csv('pop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop['Population '] = pop['Population '].str.replace(',','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop['Population ']  = pop['Population '].astype('float64')\n",
    "pop['Population ']  = pop['Population '].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pop.append({'Year ': 1999, 'Population ': 92942}, ignore_index=True)\n",
    "pop = pop.append({'Year ': 2000, 'Population ':101355}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.sort_values('Year ', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1999</td>\n",
       "      <td>92942.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2000</td>\n",
       "      <td>101355.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2001</td>\n",
       "      <td>103960.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2002</td>\n",
       "      <td>104222.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2003</td>\n",
       "      <td>103331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2004</td>\n",
       "      <td>103359.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2005</td>\n",
       "      <td>103931.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2006</td>\n",
       "      <td>104604.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2007</td>\n",
       "      <td>106361.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2008</td>\n",
       "      <td>108284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2009</td>\n",
       "      <td>108780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010</td>\n",
       "      <td>105028.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2011</td>\n",
       "      <td>105906.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>106298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>108026.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014</td>\n",
       "      <td>110056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>110516.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>112183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>113630.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year   Population \n",
       "17   1999      92942.0\n",
       "18   2000     101355.0\n",
       "8    2001     103960.0\n",
       "9    2002     104222.0\n",
       "10   2003     103331.0\n",
       "11   2004     103359.0\n",
       "12   2005     103931.0\n",
       "13   2006     104604.0\n",
       "14   2007     106361.0\n",
       "15   2008     108284.0\n",
       "16   2009     108780.0\n",
       "7    2010     105028.0\n",
       "6    2011     105906.0\n",
       "5    2012     106298.0\n",
       "4    2013     108026.0\n",
       "3    2014     110056.0\n",
       "2    2015     110516.0\n",
       "1    2016     112183.0\n",
       "0    2017     113630.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ndvi_lst:\n",
    "    i[1] = int(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_no2018 = [i for i in ndvi_lst if i[1] != 2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_2018 = [i for i in ndvi_lst if i[1] == 2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n",
      "2018\n",
      "2018\n",
      "2018\n",
      "2018\n",
      "2018\n",
      "2018\n",
      "2018\n",
      "2018\n",
      "2018\n",
      "2018\n",
      "2018\n",
      "2018\n",
      "2018\n",
      "2018\n",
      "2018\n",
      "2018\n"
     ]
    }
   ],
   "source": [
    "for i in ndvi_2018:\n",
    "    print(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999.0 1999\n",
      "1999.0 1999\n",
      "1999.0 1999\n",
      "1999.0 1999\n",
      "1999.0 1999\n",
      "1999.0 1999\n",
      "1999.0 1999\n",
      "1999.0 1999\n",
      "1999.0 1999\n",
      "1999.0 1999\n",
      "1999.0 1999\n",
      "1999.0 1999\n",
      "2000.0 2000\n",
      "2000.0 2000\n",
      "2000.0 2000\n",
      "2000.0 2000\n",
      "2000.0 2000\n",
      "2000.0 2000\n",
      "2000.0 2000\n",
      "2000.0 2000\n",
      "2000.0 2000\n",
      "2000.0 2000\n",
      "2000.0 2000\n",
      "2000.0 2000\n",
      "2000.0 2000\n",
      "2000.0 2000\n",
      "2000.0 2000\n",
      "2000.0 2000\n",
      "2000.0 2000\n",
      "2000.0 2000\n",
      "2000.0 2000\n",
      "2000.0 2000\n",
      "2000.0 2000\n",
      "2000.0 2000\n",
      "2001.0 2001\n",
      "2001.0 2001\n",
      "2001.0 2001\n",
      "2001.0 2001\n",
      "2001.0 2001\n",
      "2001.0 2001\n",
      "2001.0 2001\n",
      "2001.0 2001\n",
      "2001.0 2001\n",
      "2001.0 2001\n",
      "2001.0 2001\n",
      "2001.0 2001\n",
      "2001.0 2001\n",
      "2001.0 2001\n",
      "2001.0 2001\n",
      "2001.0 2001\n",
      "2001.0 2001\n",
      "2001.0 2001\n",
      "2001.0 2001\n",
      "2001.0 2001\n",
      "2001.0 2001\n",
      "2001.0 2001\n",
      "2001.0 2001\n",
      "2002.0 2002\n",
      "2002.0 2002\n",
      "2002.0 2002\n",
      "2002.0 2002\n",
      "2002.0 2002\n",
      "2002.0 2002\n",
      "2002.0 2002\n",
      "2002.0 2002\n",
      "2002.0 2002\n",
      "2002.0 2002\n",
      "2002.0 2002\n",
      "2002.0 2002\n",
      "2002.0 2002\n",
      "2002.0 2002\n",
      "2002.0 2002\n",
      "2002.0 2002\n",
      "2002.0 2002\n",
      "2002.0 2002\n",
      "2002.0 2002\n",
      "2002.0 2002\n",
      "2002.0 2002\n",
      "2002.0 2002\n",
      "2002.0 2002\n",
      "2003.0 2003\n",
      "2003.0 2003\n",
      "2003.0 2003\n",
      "2003.0 2003\n",
      "2003.0 2003\n",
      "2003.0 2003\n",
      "2003.0 2003\n",
      "2003.0 2003\n",
      "2003.0 2003\n",
      "2003.0 2003\n",
      "2003.0 2003\n",
      "2003.0 2003\n",
      "2003.0 2003\n",
      "2003.0 2003\n",
      "2003.0 2003\n",
      "2003.0 2003\n",
      "2003.0 2003\n",
      "2003.0 2003\n",
      "2003.0 2003\n",
      "2003.0 2003\n",
      "2004.0 2004\n",
      "2004.0 2004\n",
      "2004.0 2004\n",
      "2004.0 2004\n",
      "2004.0 2004\n",
      "2004.0 2004\n",
      "2004.0 2004\n",
      "2004.0 2004\n",
      "2004.0 2004\n",
      "2004.0 2004\n",
      "2004.0 2004\n",
      "2004.0 2004\n",
      "2004.0 2004\n",
      "2004.0 2004\n",
      "2004.0 2004\n",
      "2004.0 2004\n",
      "2004.0 2004\n",
      "2004.0 2004\n",
      "2004.0 2004\n",
      "2004.0 2004\n",
      "2004.0 2004\n",
      "2004.0 2004\n",
      "2004.0 2004\n",
      "2005.0 2005\n",
      "2005.0 2005\n",
      "2005.0 2005\n",
      "2005.0 2005\n",
      "2005.0 2005\n",
      "2005.0 2005\n",
      "2005.0 2005\n",
      "2005.0 2005\n",
      "2005.0 2005\n",
      "2005.0 2005\n",
      "2005.0 2005\n",
      "2005.0 2005\n",
      "2005.0 2005\n",
      "2005.0 2005\n",
      "2005.0 2005\n",
      "2005.0 2005\n",
      "2005.0 2005\n",
      "2005.0 2005\n",
      "2005.0 2005\n",
      "2005.0 2005\n",
      "2005.0 2005\n",
      "2005.0 2005\n",
      "2005.0 2005\n",
      "2006.0 2006\n",
      "2006.0 2006\n",
      "2006.0 2006\n",
      "2006.0 2006\n",
      "2006.0 2006\n",
      "2006.0 2006\n",
      "2006.0 2006\n",
      "2006.0 2006\n",
      "2006.0 2006\n",
      "2006.0 2006\n",
      "2006.0 2006\n",
      "2006.0 2006\n",
      "2006.0 2006\n",
      "2006.0 2006\n",
      "2006.0 2006\n",
      "2006.0 2006\n",
      "2006.0 2006\n",
      "2006.0 2006\n",
      "2006.0 2006\n",
      "2006.0 2006\n",
      "2006.0 2006\n",
      "2006.0 2006\n",
      "2007.0 2007\n",
      "2007.0 2007\n",
      "2007.0 2007\n",
      "2007.0 2007\n",
      "2007.0 2007\n",
      "2007.0 2007\n",
      "2007.0 2007\n",
      "2007.0 2007\n",
      "2007.0 2007\n",
      "2007.0 2007\n",
      "2007.0 2007\n",
      "2007.0 2007\n",
      "2007.0 2007\n",
      "2007.0 2007\n",
      "2007.0 2007\n",
      "2007.0 2007\n",
      "2007.0 2007\n",
      "2007.0 2007\n",
      "2007.0 2007\n",
      "2007.0 2007\n",
      "2007.0 2007\n",
      "2007.0 2007\n",
      "2007.0 2007\n",
      "2008.0 2008\n",
      "2008.0 2008\n",
      "2008.0 2008\n",
      "2008.0 2008\n",
      "2008.0 2008\n",
      "2008.0 2008\n",
      "2008.0 2008\n",
      "2008.0 2008\n",
      "2008.0 2008\n",
      "2008.0 2008\n",
      "2008.0 2008\n",
      "2008.0 2008\n",
      "2008.0 2008\n",
      "2008.0 2008\n",
      "2008.0 2008\n",
      "2008.0 2008\n",
      "2008.0 2008\n",
      "2008.0 2008\n",
      "2008.0 2008\n",
      "2008.0 2008\n",
      "2008.0 2008\n",
      "2008.0 2008\n",
      "2008.0 2008\n",
      "2009.0 2009\n",
      "2009.0 2009\n",
      "2009.0 2009\n",
      "2009.0 2009\n",
      "2009.0 2009\n",
      "2009.0 2009\n",
      "2009.0 2009\n",
      "2009.0 2009\n",
      "2009.0 2009\n",
      "2009.0 2009\n",
      "2009.0 2009\n",
      "2009.0 2009\n",
      "2009.0 2009\n",
      "2009.0 2009\n",
      "2009.0 2009\n",
      "2009.0 2009\n",
      "2009.0 2009\n",
      "2009.0 2009\n",
      "2009.0 2009\n",
      "2009.0 2009\n",
      "2009.0 2009\n",
      "2009.0 2009\n",
      "2010.0 2010\n",
      "2010.0 2010\n",
      "2010.0 2010\n",
      "2010.0 2010\n",
      "2010.0 2010\n",
      "2010.0 2010\n",
      "2010.0 2010\n",
      "2010.0 2010\n",
      "2010.0 2010\n",
      "2010.0 2010\n",
      "2010.0 2010\n",
      "2010.0 2010\n",
      "2010.0 2010\n",
      "2010.0 2010\n",
      "2010.0 2010\n",
      "2010.0 2010\n",
      "2010.0 2010\n",
      "2010.0 2010\n",
      "2010.0 2010\n",
      "2010.0 2010\n",
      "2010.0 2010\n",
      "2010.0 2010\n",
      "2010.0 2010\n",
      "2011.0 2011\n",
      "2011.0 2011\n",
      "2011.0 2011\n",
      "2011.0 2011\n",
      "2011.0 2011\n",
      "2011.0 2011\n",
      "2011.0 2011\n",
      "2011.0 2011\n",
      "2011.0 2011\n",
      "2011.0 2011\n",
      "2011.0 2011\n",
      "2011.0 2011\n",
      "2011.0 2011\n",
      "2011.0 2011\n",
      "2011.0 2011\n",
      "2011.0 2011\n",
      "2011.0 2011\n",
      "2011.0 2011\n",
      "2011.0 2011\n",
      "2011.0 2011\n",
      "2011.0 2011\n",
      "2011.0 2011\n",
      "2011.0 2011\n",
      "2012.0 2012\n",
      "2012.0 2012\n",
      "2012.0 2012\n",
      "2012.0 2012\n",
      "2012.0 2012\n",
      "2012.0 2012\n",
      "2012.0 2012\n",
      "2012.0 2012\n",
      "2012.0 2012\n",
      "2012.0 2012\n",
      "2012.0 2012\n",
      "2012.0 2012\n",
      "2012.0 2012\n",
      "2012.0 2012\n",
      "2012.0 2012\n",
      "2012.0 2012\n",
      "2012.0 2012\n",
      "2012.0 2012\n",
      "2012.0 2012\n",
      "2012.0 2012\n",
      "2012.0 2012\n",
      "2013.0 2013\n",
      "2013.0 2013\n",
      "2013.0 2013\n",
      "2013.0 2013\n",
      "2013.0 2013\n",
      "2013.0 2013\n",
      "2013.0 2013\n",
      "2013.0 2013\n",
      "2013.0 2013\n",
      "2013.0 2013\n",
      "2013.0 2013\n",
      "2013.0 2013\n",
      "2013.0 2013\n",
      "2013.0 2013\n",
      "2013.0 2013\n",
      "2013.0 2013\n",
      "2013.0 2013\n",
      "2013.0 2013\n",
      "2013.0 2013\n",
      "2013.0 2013\n",
      "2013.0 2013\n",
      "2013.0 2013\n",
      "2013.0 2013\n",
      "2014.0 2014\n",
      "2014.0 2014\n",
      "2014.0 2014\n",
      "2014.0 2014\n",
      "2014.0 2014\n",
      "2014.0 2014\n",
      "2014.0 2014\n",
      "2014.0 2014\n",
      "2014.0 2014\n",
      "2014.0 2014\n",
      "2014.0 2014\n",
      "2014.0 2014\n",
      "2014.0 2014\n",
      "2014.0 2014\n",
      "2014.0 2014\n",
      "2014.0 2014\n",
      "2014.0 2014\n",
      "2014.0 2014\n",
      "2014.0 2014\n",
      "2014.0 2014\n",
      "2014.0 2014\n",
      "2014.0 2014\n",
      "2014.0 2014\n",
      "2015.0 2015\n",
      "2015.0 2015\n",
      "2015.0 2015\n",
      "2015.0 2015\n",
      "2015.0 2015\n",
      "2015.0 2015\n",
      "2015.0 2015\n",
      "2015.0 2015\n",
      "2015.0 2015\n",
      "2015.0 2015\n",
      "2015.0 2015\n",
      "2015.0 2015\n",
      "2015.0 2015\n",
      "2015.0 2015\n",
      "2015.0 2015\n",
      "2015.0 2015\n",
      "2015.0 2015\n",
      "2015.0 2015\n",
      "2015.0 2015\n",
      "2015.0 2015\n",
      "2015.0 2015\n",
      "2015.0 2015\n",
      "2015.0 2015\n",
      "2016.0 2016\n",
      "2016.0 2016\n",
      "2016.0 2016\n",
      "2016.0 2016\n",
      "2016.0 2016\n",
      "2016.0 2016\n",
      "2016.0 2016\n",
      "2016.0 2016\n",
      "2016.0 2016\n",
      "2016.0 2016\n",
      "2016.0 2016\n",
      "2016.0 2016\n",
      "2016.0 2016\n",
      "2016.0 2016\n",
      "2016.0 2016\n",
      "2016.0 2016\n",
      "2016.0 2016\n",
      "2016.0 2016\n",
      "2016.0 2016\n",
      "2016.0 2016\n",
      "2016.0 2016\n",
      "2016.0 2016\n",
      "2016.0 2016\n",
      "2017.0 2017\n",
      "2017.0 2017\n",
      "2017.0 2017\n",
      "2017.0 2017\n",
      "2017.0 2017\n",
      "2017.0 2017\n",
      "2017.0 2017\n",
      "2017.0 2017\n",
      "2017.0 2017\n",
      "2017.0 2017\n",
      "2017.0 2017\n",
      "2017.0 2017\n",
      "2017.0 2017\n",
      "2017.0 2017\n",
      "2017.0 2017\n",
      "2017.0 2017\n",
      "2017.0 2017\n",
      "2017.0 2017\n",
      "2017.0 2017\n",
      "2017.0 2017\n",
      "2017.0 2017\n",
      "2017.0 2017\n",
      "2017.0 2017\n"
     ]
    }
   ],
   "source": [
    "for i in ndvi_no2018:\n",
    "    year = i[1]\n",
    "    for idx, row in pop.iterrows():\n",
    "        if row['Year '] == year:\n",
    "            print(row['Year '], year)\n",
    "            i.append(row['Population '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197, 264)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndvi_no2018[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_img_data = np.array([i[0] for i in ndvi_no2018]).reshape(-1,197,264,1)\n",
    "tr_lbl_data = np.array([i[2] for i in ndvi_no2018])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 197, 264, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tr_img_data.reshape(-1, 418))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_lbl_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92942.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_lbl_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tr_img_data, tr_lbl_data, test_size =0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(376, 197, 264, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 197, 264, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(376,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# First Conv\n",
    "model.add(Convolution2D(filters = 32,         # I specify 6 filters.\n",
    "                        kernel_size = 3,          # means a 3x3 filter\n",
    "                        activation = 'relu',\n",
    "                     padding='same',\n",
    "                 input_shape = (197, 264, 1)# Rectified Linear Unit activation\n",
    "                ))\n",
    "model.add(MaxPooling2D(pool_size = 5, padding='same'))\n",
    "\n",
    "# Second Conv\n",
    "model.add(Conv2D(filters = 50,         # I specify 6 filters.\n",
    "                        kernel_size = 3,     # means a 3x3 filter\n",
    "                        activation = 'relu',\n",
    "                 padding='same'# Rectified Linear Unit activation\n",
    "                ))\n",
    "model.add(MaxPooling2D(pool_size= 5, padding='same'))\n",
    "\n",
    "#Third conv\n",
    "model.add(Conv2D(filters = 80,         # I specify 6 filters.\n",
    "                        kernel_size = 3,     # means a 3x3 filter\n",
    "                        activation = 'relu',\n",
    "                 padding='same'# Rectified Linear Unit activation\n",
    "                ))\n",
    "model.add(MaxPooling2D(pool_size = 5, padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation = 'relu')) \n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation = 'relu'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=1, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mean_squared_error',\n",
    "# Categorical cross-entropy is common for unordered discrete predictions.\n",
    "              optimizer = 'adam',\n",
    "# Adaptive Moment Estimation, \"sophisticated gradient descent\"\n",
    "              metrics = [mean_squared_error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 376 samples, validate on 42 samples\n",
      "Epoch 1/100\n",
      "376/376 [==============================] - 11s 30ms/step - loss: 11319146997.1064 - mean_squared_error: 11319146997.1064 - val_loss: 11210031542.8571 - val_mean_squared_error: 11210031542.8571\n",
      "Epoch 2/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 11279511573.7872 - mean_squared_error: 11279511573.7872 - val_loss: 11194322505.1429 - val_mean_squared_error: 11194322505.1429\n",
      "Epoch 3/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 11256286338.7234 - mean_squared_error: 11256286338.7234 - val_loss: 11178775844.5714 - val_mean_squared_error: 11178775844.5714\n",
      "Epoch 4/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 11244683721.5319 - mean_squared_error: 11244683721.5319 - val_loss: 11168987964.9524 - val_mean_squared_error: 11168987964.9524\n",
      "Epoch 5/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 11216014793.5319 - mean_squared_error: 11216014793.5319 - val_loss: 11136419742.4762 - val_mean_squared_error: 11136419742.4762\n",
      "Epoch 6/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 11194141085.9574 - mean_squared_error: 11194141085.9574 - val_loss: 11076082883.0476 - val_mean_squared_error: 11076082883.0476\n",
      "Epoch 7/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 11269145970.3830 - mean_squared_error: 11269145970.3830 - val_loss: 10889455859.8095 - val_mean_squared_error: 10889455859.8095\n",
      "Epoch 8/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 10990816909.6170 - mean_squared_error: 10990816909.6170 - val_loss: 10916168411.4286 - val_mean_squared_error: 10916168411.4286\n",
      "Epoch 9/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 10837586377.5319 - mean_squared_error: 10837586377.5319 - val_loss: 10627465508.5714 - val_mean_squared_error: 10627465508.5714\n",
      "Epoch 10/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 10384176106.2128 - mean_squared_error: 10384176106.2128 - val_loss: 9883151798.8571 - val_mean_squared_error: 9883151798.8571\n",
      "Epoch 11/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 9247260072.8511 - mean_squared_error: 9247260072.8511 - val_loss: 8191660129.5238 - val_mean_squared_error: 8191660129.5238\n",
      "Epoch 12/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 8238844993.3617 - mean_squared_error: 8238844993.3617 - val_loss: 5444012275.8095 - val_mean_squared_error: 5444012275.8095\n",
      "Epoch 13/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 4732159226.5532 - mean_squared_error: 4732159226.5532 - val_loss: 4162571654.0952 - val_mean_squared_error: 4162571654.0952\n",
      "Epoch 14/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 3404699032.5106 - mean_squared_error: 3404699032.5106 - val_loss: 3101415680.0000 - val_mean_squared_error: 3101415680.0000\n",
      "Epoch 15/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 2529896050.3830 - mean_squared_error: 2529896050.3830 - val_loss: 2454105039.2381 - val_mean_squared_error: 2454105039.2381\n",
      "Epoch 16/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 1933670391.8298 - mean_squared_error: 1933670391.8298 - val_loss: 1857507175.6190 - val_mean_squared_error: 1857507175.6190\n",
      "Epoch 17/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 2436393670.8085 - mean_squared_error: 2436393670.8085 - val_loss: 1561255058.2857 - val_mean_squared_error: 1561255058.2857\n",
      "Epoch 18/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 1269044194.0426 - mean_squared_error: 1269044194.0426 - val_loss: 1310349196.1905 - val_mean_squared_error: 1310349196.1905\n",
      "Epoch 19/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 969939841.3617 - mean_squared_error: 969939841.3617 - val_loss: 942490922.6667 - val_mean_squared_error: 942490922.6667\n",
      "Epoch 20/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 754471529.5319 - mean_squared_error: 754471529.5319 - val_loss: 733625929.1429 - val_mean_squared_error: 733625929.1429\n",
      "Epoch 21/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 560175015.4894 - mean_squared_error: 560175015.4894 - val_loss: 578765592.3810 - val_mean_squared_error: 578765592.3810\n",
      "Epoch 22/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 476414739.7447 - mean_squared_error: 476414739.7447 - val_loss: 451161784.3810 - val_mean_squared_error: 451161784.3810\n",
      "Epoch 23/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 380426443.5745 - mean_squared_error: 380426443.5745 - val_loss: 363794020.5714 - val_mean_squared_error: 363794020.5714\n",
      "Epoch 24/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 328902147.4043 - mean_squared_error: 328902147.4043 - val_loss: 307930368.7619 - val_mean_squared_error: 307930368.7619\n",
      "Epoch 25/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 262647891.7447 - mean_squared_error: 262647891.7447 - val_loss: 246068707.0476 - val_mean_squared_error: 246068707.0476\n",
      "Epoch 26/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 246935636.4255 - mean_squared_error: 246935636.4255 - val_loss: 207364577.5238 - val_mean_squared_error: 207364577.5238\n",
      "Epoch 27/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 195899006.2979 - mean_squared_error: 195899006.2979 - val_loss: 179133976.7619 - val_mean_squared_error: 179133976.7619\n",
      "Epoch 28/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 183465184.3404 - mean_squared_error: 183465184.3404 - val_loss: 151712819.4286 - val_mean_squared_error: 151712819.4286\n",
      "Epoch 29/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 175483617.0213 - mean_squared_error: 175483617.0213 - val_loss: 136197801.1429 - val_mean_squared_error: 136197801.1429\n",
      "Epoch 30/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 136340072.5106 - mean_squared_error: 136340072.5106 - val_loss: 115628337.9048 - val_mean_squared_error: 115628337.9048\n",
      "Epoch 31/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 122355824.6809 - mean_squared_error: 122355824.6809 - val_loss: 103639840.0000 - val_mean_squared_error: 103639840.0000\n",
      "Epoch 32/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 115237281.5319 - mean_squared_error: 115237281.5319 - val_loss: 92815391.2381 - val_mean_squared_error: 92815391.2381\n",
      "Epoch 33/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 107988189.2766 - mean_squared_error: 107988189.2766 - val_loss: 83888756.0000 - val_mean_squared_error: 83888756.0000\n",
      "Epoch 34/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 109527641.7021 - mean_squared_error: 109527641.7021 - val_loss: 78855622.4762 - val_mean_squared_error: 78855622.4762\n",
      "Epoch 35/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 105786339.9149 - mean_squared_error: 105786339.9149 - val_loss: 69584452.1905 - val_mean_squared_error: 69584452.1905\n",
      "Epoch 36/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 87471977.2766 - mean_squared_error: 87471977.2766 - val_loss: 62952463.0476 - val_mean_squared_error: 62952463.0476\n",
      "Epoch 37/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 80418537.1915 - mean_squared_error: 80418537.1915 - val_loss: 59138068.0000 - val_mean_squared_error: 59138068.0000\n",
      "Epoch 38/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 94597563.4043 - mean_squared_error: 94597563.4043 - val_loss: 58449758.0952 - val_mean_squared_error: 58449758.0952\n",
      "Epoch 39/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 90365594.8936 - mean_squared_error: 90365594.8936 - val_loss: 54921320.7619 - val_mean_squared_error: 54921320.7619\n",
      "Epoch 40/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 80164054.2979 - mean_squared_error: 80164054.2979 - val_loss: 50165908.1905 - val_mean_squared_error: 50165908.1905\n",
      "Epoch 41/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 77900252.7660 - mean_squared_error: 77900252.7660 - val_loss: 45776444.8571 - val_mean_squared_error: 45776444.8571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 71947216.5106 - mean_squared_error: 71947216.5106 - val_loss: 43953011.7143 - val_mean_squared_error: 43953011.7143\n",
      "Epoch 43/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 66298299.7447 - mean_squared_error: 66298299.7447 - val_loss: 43093090.9524 - val_mean_squared_error: 43093090.9524\n",
      "Epoch 44/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 67939748.7660 - mean_squared_error: 67939748.7660 - val_loss: 40623399.5238 - val_mean_squared_error: 40623399.5238\n",
      "Epoch 45/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 76271168.9362 - mean_squared_error: 76271168.9362 - val_loss: 38653046.9524 - val_mean_squared_error: 38653046.9524\n",
      "Epoch 46/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 68696923.6596 - mean_squared_error: 68696923.6596 - val_loss: 40469583.4286 - val_mean_squared_error: 40469583.4286\n",
      "Epoch 47/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 71818221.7872 - mean_squared_error: 71818221.7872 - val_loss: 37528952.9524 - val_mean_squared_error: 37528952.9524\n",
      "Epoch 48/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 65874694.4681 - mean_squared_error: 65874694.4681 - val_loss: 35308569.4286 - val_mean_squared_error: 35308569.4286\n",
      "Epoch 49/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 69393441.7021 - mean_squared_error: 69393441.7021 - val_loss: 36053516.0952 - val_mean_squared_error: 36053516.0952\n",
      "Epoch 50/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 69242788.5957 - mean_squared_error: 69242788.5957 - val_loss: 33062804.3810 - val_mean_squared_error: 33062804.3810\n",
      "Epoch 51/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 61362550.4681 - mean_squared_error: 61362550.4681 - val_loss: 31962910.2857 - val_mean_squared_error: 31962910.2857\n",
      "Epoch 52/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 60052344.0000 - mean_squared_error: 60052344.0000 - val_loss: 33573554.1905 - val_mean_squared_error: 33573554.1905\n",
      "Epoch 53/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 65428505.3617 - mean_squared_error: 65428505.3617 - val_loss: 32101782.6667 - val_mean_squared_error: 32101782.6667\n",
      "Epoch 54/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 57427719.7447 - mean_squared_error: 57427719.7447 - val_loss: 31637550.4762 - val_mean_squared_error: 31637550.4762\n",
      "Epoch 55/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 54497269.1064 - mean_squared_error: 54497269.1064 - val_loss: 29796502.2857 - val_mean_squared_error: 29796502.2857\n",
      "Epoch 56/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 58689518.6383 - mean_squared_error: 58689518.6383 - val_loss: 30592045.2381 - val_mean_squared_error: 30592045.2381\n",
      "Epoch 57/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 64456797.0213 - mean_squared_error: 64456797.0213 - val_loss: 28772207.4286 - val_mean_squared_error: 28772207.4286\n",
      "Epoch 58/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 62700561.3617 - mean_squared_error: 62700561.3617 - val_loss: 30209520.7619 - val_mean_squared_error: 30209520.7619\n",
      "Epoch 59/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 52460135.1489 - mean_squared_error: 52460135.1489 - val_loss: 29319675.6190 - val_mean_squared_error: 29319675.6190\n",
      "Epoch 60/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 59924272.0000 - mean_squared_error: 59924272.0000 - val_loss: 28312396.3810 - val_mean_squared_error: 28312396.3810\n",
      "Epoch 61/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 53694652.4255 - mean_squared_error: 53694652.4255 - val_loss: 27301437.6190 - val_mean_squared_error: 27301437.6190\n",
      "Epoch 62/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 62220509.1064 - mean_squared_error: 62220509.1064 - val_loss: 27115787.5238 - val_mean_squared_error: 27115787.5238\n",
      "Epoch 63/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 61288174.6383 - mean_squared_error: 61288174.6383 - val_loss: 27842477.5238 - val_mean_squared_error: 27842477.5238\n",
      "Epoch 64/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 65431203.5745 - mean_squared_error: 65431203.5745 - val_loss: 25985715.8571 - val_mean_squared_error: 25985715.8571\n",
      "Epoch 65/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 50377613.6170 - mean_squared_error: 50377613.6170 - val_loss: 27307733.0476 - val_mean_squared_error: 27307733.0476\n",
      "Epoch 66/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 57612375.7447 - mean_squared_error: 57612375.7447 - val_loss: 26666337.5238 - val_mean_squared_error: 26666337.5238\n",
      "Epoch 67/100\n",
      "376/376 [==============================] - 11s 29ms/step - loss: 59819479.5745 - mean_squared_error: 59819479.5745 - val_loss: 26181653.2381 - val_mean_squared_error: 26181653.2381\n",
      "Epoch 00067: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f38cdcea0f0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 197, 264, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 40, 53, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 40, 53, 50)        14450     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 11, 50)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 11, 80)         36080     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 3, 80)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2, 3, 80)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 480)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               246272    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 297,635\n",
      "Trainable params: 297,635\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[109648.79 ],\n",
       "       [103298.47 ],\n",
       "       [105486.81 ],\n",
       "       [106514.03 ],\n",
       "       [105731.6  ],\n",
       "       [109944.32 ],\n",
       "       [107261.586],\n",
       "       [106708.98 ],\n",
       "       [107205.53 ],\n",
       "       [107948.02 ],\n",
       "       [104917.57 ],\n",
       "       [110237.164],\n",
       "       [109833.945],\n",
       "       [104910.91 ],\n",
       "       [105920.4  ],\n",
       "       [111003.61 ],\n",
       "       [109949.43 ],\n",
       "       [105580.03 ],\n",
       "       [105589.24 ],\n",
       "       [104949.85 ],\n",
       "       [106464.03 ],\n",
       "       [107206.85 ],\n",
       "       [106394.99 ],\n",
       "       [105210.805],\n",
       "       [103947.46 ],\n",
       "       [106118.51 ],\n",
       "       [107453.586],\n",
       "       [106938.43 ],\n",
       "       [104442.41 ],\n",
       "       [105159.055],\n",
       "       [109914.69 ],\n",
       "       [107689.16 ],\n",
       "       [105395.38 ],\n",
       "       [104988.195],\n",
       "       [109700.9  ],\n",
       "       [107634.99 ],\n",
       "       [104527.04 ],\n",
       "       [106212.195],\n",
       "       [106138.69 ],\n",
       "       [107691.49 ],\n",
       "       [105655.33 ],\n",
       "       [106798.25 ]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5116.801038182451\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(mean_squared_error(test_predict, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
